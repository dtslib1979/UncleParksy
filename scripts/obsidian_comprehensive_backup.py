#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ UncleParksy ì˜µì‹œë””ì–¸ ì¢…í•© ë°±ì—… ì‹œìŠ¤í…œ
í˜„ì¬ ì„¤ì •ì— ë”°ë¼ ëª¨ë“  ì½˜í…ì¸ ë¥¼ Obsidianìœ¼ë¡œ ì™„ì „ ë°±ì—…

ì‘ê°€ì§€ë§ìƒ ë°•ì”¨ì˜ ë§ˆê°ì‘ì—…ì„ ìœ„í•œ í†µí•© ë°±ì—… ì†”ë£¨ì…˜
"""

import os
import json
import shutil
import subprocess
import time
from pathlib import Path
from datetime import datetime
import logging
import sys

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('_obsidian/_imports/backup.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class ObsidianComprehensiveBackup:
    """ğŸ¯ ì˜µì‹œë””ì–¸ ì¢…í•© ë°±ì—… ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.root_dir = Path(".")
        self.obsidian_imports = Path("_obsidian/_imports")
        self.backup_dir = Path("backup")
        self.archive_dir = Path("archive") 
        self.category_dir = Path("category")
        self.assets_dir = Path("assets")
        
        # Obsidian ë°±ì—… êµ¬ì¡°
        self.obsidian_raw = self.obsidian_imports / "html_raw"
        self.obsidian_md = self.obsidian_imports / "html_md"
        self.obsidian_assets = self.obsidian_imports / "assets"
        self.obsidian_category = self.obsidian_imports / "category"
        self.obsidian_backup = self.obsidian_imports / "backup"
        self.obsidian_archive = self.obsidian_imports / "archive"
        
        self.setup_obsidian_structure()

    def setup_obsidian_structure(self):
        """ğŸ—ï¸ Obsidian ë°±ì—… ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ì •"""
        logger.info("ğŸ—ï¸ Obsidian ë°±ì—… ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ì •...")
        
        directories = [
            self.obsidian_imports,
            self.obsidian_raw,
            self.obsidian_md,
            self.obsidian_assets,
            self.obsidian_category,
            self.obsidian_backup,
            self.obsidian_archive
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸ“ ë””ë ‰í† ë¦¬ ì¤€ë¹„: {directory}")

    def run_comprehensive_backup(self) -> bool:
        """ğŸš€ ì¢…í•© ë°±ì—… ì‹¤í–‰ - í˜„ì¬ ì„¤ì •ì— ë”°ë¼ ëª¨ë“  ì½˜í…ì¸  ë°±ì—…"""
        logger.info("ğŸ¯ ===== ì˜µì‹œë””ì–¸ ì¢…í•© ë°±ì—… ì‹œì‘ =====")
        logger.info("ğŸ“ í˜„ì¬ ì„¤ì •ì— ë”°ë¼ ëª¨ë“  ì½˜í…ì¸ ë¥¼ Obsidianìœ¼ë¡œ ë°±ì—…í•©ë‹ˆë‹¤")
        
        start_time = datetime.now()
        backup_summary = {
            "timestamp": start_time.isoformat(),
            "components": {},
            "total_files": 0,
            "errors": []
        }
        
        try:
            # 1ë‹¨ê³„: Tistory ìµœì‹  ë°±ì—… ì‹¤í–‰
            logger.info("\nğŸ”¥ 1ë‹¨ê³„: Tistory RSS ë°±ì—… ì‹¤í–‰")
            tistory_result = self._run_tistory_backup()
            backup_summary["components"]["tistory"] = tistory_result
            
            # 2ë‹¨ê³„: ë°±ì—… íŒŒì¼ì„ Obsidianìœ¼ë¡œ ë¯¸ëŸ¬ë§
            logger.info("\nğŸ“„ 2ë‹¨ê³„: ë°±ì—… íŒŒì¼ Obsidian ë¯¸ëŸ¬ë§")
            backup_mirror_result = self._mirror_backup_to_obsidian()
            backup_summary["components"]["backup_mirror"] = backup_mirror_result
            
            # 3ë‹¨ê³„: ì•„ì¹´ì´ë¸Œ íŒŒì¼ì„ Obsidianìœ¼ë¡œ ë¯¸ëŸ¬ë§
            logger.info("\nğŸ“š 3ë‹¨ê³„: ì•„ì¹´ì´ë¸Œ íŒŒì¼ Obsidian ë¯¸ëŸ¬ë§")
            archive_mirror_result = self._mirror_archive_to_obsidian()
            backup_summary["components"]["archive_mirror"] = archive_mirror_result
            
            # 4ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ íŒŒì¼ì„ Obsidianìœ¼ë¡œ ë™ê¸°í™” (RAW + Markdown)
            logger.info("\nğŸ—‚ï¸ 4ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ íŒŒì¼ Obsidian ë™ê¸°í™”")
            category_sync_result = self._sync_category_to_obsidian()
            backup_summary["components"]["category_sync"] = category_sync_result
            
            # 5ë‹¨ê³„: Assets ë°±ì—…
            logger.info("\nğŸ¨ 5ë‹¨ê³„: Assets ë°±ì—…")
            assets_result = self._backup_assets_to_obsidian()
            backup_summary["components"]["assets"] = assets_result
            
            # 6ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ë° ì„¤ì • ë°±ì—…
            logger.info("\nâš™ï¸ 6ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ë° ì„¤ì • ë°±ì—…")
            metadata_result = self._backup_metadata_to_obsidian()
            backup_summary["components"]["metadata"] = metadata_result
            
            # 7ë‹¨ê³„: ë°±ì—… ìš”ì•½ ë° ì¸ë±ìŠ¤ ìƒì„±
            logger.info("\nğŸ“‹ 7ë‹¨ê³„: ë°±ì—… ìš”ì•½ ë° ì¸ë±ìŠ¤ ìƒì„±")
            self._generate_backup_index(backup_summary)
            
            # ê³„ì‚° ì´ê³„
            total_files = sum(
                result.get("files_processed", 0) 
                for result in backup_summary["components"].values()
            )
            backup_summary["total_files"] = total_files
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            logger.info(f"\nâœ… ===== ì˜µì‹œë””ì–¸ ì¢…í•© ë°±ì—… ì™„ë£Œ =====")
            logger.info(f"ğŸ• ì†Œìš”ì‹œê°„: {duration:.2f}ì´ˆ")
            logger.info(f"ğŸ“Š ì´ ì²˜ë¦¬ íŒŒì¼: {total_files}ê°œ")
            logger.info(f"ğŸ“ ë°±ì—… ìœ„ì¹˜: {self.obsidian_imports}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì¢…í•© ë°±ì—… ì‹¤íŒ¨: {e}")
            backup_summary["errors"].append(str(e))
            return False
    
    def _run_tistory_backup(self) -> dict:
        """ğŸ”¥ Tistory RSS ë°±ì—… ì‹¤í–‰"""
        logger.info("ğŸ”¥ Tistory RSS ë°±ì—… ì‹œì‘...")
        
        try:
            result = subprocess.run([
                sys.executable, 'scripts/tistory_backup.py'
            ], capture_output=True, text=True, cwd=self.root_dir)
            
            if result.returncode == 0:
                # ìƒˆ íŒŒì¼ ê°œìˆ˜ íŒŒì‹±
                output = result.stdout
                if "ìƒˆ íŒŒì¼:" in output:
                    import re
                    match = re.search(r'ìƒˆ íŒŒì¼: (\d+)ê°œ', output)
                    new_files = int(match.group(1)) if match else 0
                else:
                    new_files = 0
                
                logger.info(f"âœ… Tistory ë°±ì—… ì™„ë£Œ: {new_files}ê°œ ìƒˆ íŒŒì¼")
                return {
                    "status": "success",
                    "files_processed": new_files,
                    "message": f"Tistory RSS ë°±ì—… ì™„ë£Œ: {new_files}ê°œ ìƒˆ íŒŒì¼"
                }
            else:
                logger.error(f"âŒ Tistory ë°±ì—… ì‹¤íŒ¨: {result.stderr}")
                return {
                    "status": "error",
                    "files_processed": 0,
                    "message": f"Tistory ë°±ì—… ì‹¤íŒ¨: {result.stderr}"
                }
                
        except Exception as e:
            logger.error(f"âŒ Tistory ë°±ì—… ì˜¤ë¥˜: {e}")
            return {
                "status": "error",
                "files_processed": 0,
                "message": f"Tistory ë°±ì—… ì˜¤ë¥˜: {e}"
            }
    
    def _mirror_backup_to_obsidian(self) -> dict:
        """ğŸ“„ ë°±ì—… íŒŒì¼ì„ Obsidianìœ¼ë¡œ ë¯¸ëŸ¬ë§"""
        logger.info("ğŸ“„ ë°±ì—… íŒŒì¼ Obsidian ë¯¸ëŸ¬ë§ ì‹œì‘...")
        
        mirrored_count = 0
        
        try:
            # backup/raw í´ë”ì˜ HTML íŒŒì¼ë“¤ì„ _obsidian/_imports/backupìœ¼ë¡œ ë³µì‚¬
            backup_raw_dir = self.backup_dir / "raw"
            if backup_raw_dir.exists():
                for html_file in backup_raw_dir.glob("*.html"):
                    dst_file = self.obsidian_backup / html_file.name
                    
                    # ìƒˆ íŒŒì¼ì´ê±°ë‚˜ ìˆ˜ì •ëœ íŒŒì¼ë§Œ ë³µì‚¬
                    if (not dst_file.exists() or 
                        html_file.stat().st_mtime > dst_file.stat().st_mtime):
                        
                        shutil.copy2(html_file, dst_file)
                        mirrored_count += 1
                        logger.info(f"ğŸ“„ ë°±ì—… ë³µì‚¬: {html_file.name}")
            
            # backup í´ë”ì˜ ì§ì ‘ HTML íŒŒì¼ë“¤ë„ ë³µì‚¬
            for html_file in self.backup_dir.glob("*.html"):
                dst_file = self.obsidian_backup / html_file.name
                
                if (not dst_file.exists() or 
                    html_file.stat().st_mtime > dst_file.stat().st_mtime):
                    
                    shutil.copy2(html_file, dst_file)
                    mirrored_count += 1
                    logger.info(f"ğŸ“„ ë°±ì—… ë³µì‚¬: {html_file.name}")
            
            logger.info(f"âœ… ë°±ì—… íŒŒì¼ ë¯¸ëŸ¬ë§ ì™„ë£Œ: {mirrored_count}ê°œ íŒŒì¼")
            return {
                "status": "success",
                "files_processed": mirrored_count,
                "message": f"ë°±ì—… íŒŒì¼ ë¯¸ëŸ¬ë§ ì™„ë£Œ: {mirrored_count}ê°œ íŒŒì¼"
            }
            
        except Exception as e:
            logger.error(f"âŒ ë°±ì—… íŒŒì¼ ë¯¸ëŸ¬ë§ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "files_processed": 0,
                "message": f"ë°±ì—… íŒŒì¼ ë¯¸ëŸ¬ë§ ì‹¤íŒ¨: {e}"
            }
    
    def _mirror_archive_to_obsidian(self) -> dict:
        """ğŸ“š ì•„ì¹´ì´ë¸Œ íŒŒì¼ì„ Obsidianìœ¼ë¡œ ë¯¸ëŸ¬ë§"""
        logger.info("ğŸ“š ì•„ì¹´ì´ë¸Œ íŒŒì¼ Obsidian ë¯¸ëŸ¬ë§ ì‹œì‘...")
        
        mirrored_count = 0
        
        try:
            # archive í´ë”ì˜ HTML íŒŒì¼ë“¤ì„ _obsidian/_imports/archiveë¡œ ë³µì‚¬
            for html_file in self.archive_dir.glob("*.html"):
                if html_file.name == "index.html":
                    continue  # index.html ì œì™¸
                
                dst_file = self.obsidian_archive / html_file.name
                
                # ìƒˆ íŒŒì¼ì´ê±°ë‚˜ ìˆ˜ì •ëœ íŒŒì¼ë§Œ ë³µì‚¬
                if (not dst_file.exists() or 
                    html_file.stat().st_mtime > dst_file.stat().st_mtime):
                    
                    shutil.copy2(html_file, dst_file)
                    mirrored_count += 1
                    logger.info(f"ğŸ“š ì•„ì¹´ì´ë¸Œ ë³µì‚¬: {html_file.name}")
            
            logger.info(f"âœ… ì•„ì¹´ì´ë¸Œ íŒŒì¼ ë¯¸ëŸ¬ë§ ì™„ë£Œ: {mirrored_count}ê°œ íŒŒì¼")
            return {
                "status": "success",
                "files_processed": mirrored_count,
                "message": f"ì•„ì¹´ì´ë¸Œ íŒŒì¼ ë¯¸ëŸ¬ë§ ì™„ë£Œ: {mirrored_count}ê°œ íŒŒì¼"
            }
            
        except Exception as e:
            logger.error(f"âŒ ì•„ì¹´ì´ë¸Œ íŒŒì¼ ë¯¸ëŸ¬ë§ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "files_processed": 0,
                "message": f"ì•„ì¹´ì´ë¸Œ íŒŒì¼ ë¯¸ëŸ¬ë§ ì‹¤íŒ¨: {e}"
            }
    
    def _sync_category_to_obsidian(self) -> dict:
        """ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ íŒŒì¼ì„ Obsidianìœ¼ë¡œ ë™ê¸°í™” (ê¸°ì¡´ ì›Œí¬í”Œë¡œìš° ì¬ì‚¬ìš©)"""
        logger.info("ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ íŒŒì¼ Obsidian ë™ê¸°í™” ì‹œì‘...")
        
        try:
            # í˜„ì¬ ì„¤ì •ì— ë”°ë¥¸ ì¹´í…Œê³ ë¦¬ ë™ê¸°í™” (ê¸°ì¡´ ì›Œí¬í”Œë¡œìš° ë¡œì§ ì‚¬ìš©)
            synced_files = 0
            converted_files = 0
            
            # RAW HTML ë™ê¸°í™”
            if self.category_dir.exists():
                categories = [
                    "blog-transformation",
                    "device-chronicles", 
                    "system-configuration",
                    "thought-archaeology",
                    "webappsbook-codex",
                    "webappsbookcast",
                    "writers-path"
                ]
                
                for category in categories:
                    category_path = self.category_dir / category
                    if category_path.exists():
                        dst_category_path = self.obsidian_raw / category
                        dst_category_path.mkdir(parents=True, exist_ok=True)
                        
                        # HTML íŒŒì¼ ë³µì‚¬
                        for html_file in category_path.glob("*.html"):
                            dst_file = dst_category_path / html_file.name
                            
                            if (not dst_file.exists() or 
                                html_file.stat().st_mtime > dst_file.stat().st_mtime):
                                
                                shutil.copy2(html_file, dst_file)
                                synced_files += 1
                                logger.info(f"ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ ë™ê¸°í™”: {category}/{html_file.name}")
                
                # HTML â†’ Markdown ë³€í™˜
                logger.info("ğŸ”„ HTML â†’ Markdown ë³€í™˜ ì‹œì‘...")
                
                for category in categories:
                    category_path = self.category_dir / category
                    if category_path.exists():
                        dst_md_category = self.obsidian_md / category
                        dst_md_category.mkdir(parents=True, exist_ok=True)
                        
                        for html_file in category_path.glob("*.html"):
                            md_file = dst_md_category / f"{html_file.stem}.md"
                            
                            # Pandocìœ¼ë¡œ ë³€í™˜ (ê°€ëŠ¥í•œ ê²½ìš°)
                            try:
                                result = subprocess.run([
                                    'pandoc', str(html_file), 
                                    '-f', 'html', '-t', 'gfm', 
                                    '-o', str(md_file)
                                ], capture_output=True, text=True, timeout=30)
                                
                                if result.returncode == 0:
                                    converted_files += 1
                                    logger.info(f"ğŸ“ Markdown ë³€í™˜: {category}/{html_file.stem}.md")
                                else:
                                    logger.warning(f"âš ï¸ Markdown ë³€í™˜ ì‹¤íŒ¨: {html_file.name}")
                                    
                            except (subprocess.TimeoutExpired, FileNotFoundError):
                                # Pandocì´ ì—†ê±°ë‚˜ ì‹œê°„ ì´ˆê³¼ì‹œ ê¸°ë³¸ ë³€í™˜
                                self._basic_html_to_markdown(html_file, md_file)
                                converted_files += 1
                                logger.info(f"ğŸ“ ê¸°ë³¸ Markdown ë³€í™˜: {category}/{html_file.stem}.md")
            
            total_processed = synced_files + converted_files
            logger.info(f"âœ… ì¹´í…Œê³ ë¦¬ ë™ê¸°í™” ì™„ë£Œ: RAW {synced_files}ê°œ, MD {converted_files}ê°œ")
            return {
                "status": "success",
                "files_processed": total_processed,
                "message": f"ì¹´í…Œê³ ë¦¬ ë™ê¸°í™” ì™„ë£Œ: RAW {synced_files}ê°œ, MD {converted_files}ê°œ"
            }
            
        except Exception as e:
            logger.error(f"âŒ ì¹´í…Œê³ ë¦¬ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "files_processed": 0,
                "message": f"ì¹´í…Œê³ ë¦¬ ë™ê¸°í™” ì‹¤íŒ¨: {e}"
            }
    
    def _basic_html_to_markdown(self, html_file: Path, md_file: Path):
        """ğŸ“ ê¸°ë³¸ì ì¸ HTML â†’ Markdown ë³€í™˜ (Pandoc ì—†ì„ ë•Œ)"""
        try:
            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            # ê°„ë‹¨í•œ HTML â†’ Markdown ë³€í™˜
            import re
            
            # HTML íƒœê·¸ ì œê±° ë° ê¸°ë³¸ ë³€í™˜
            content = html_content
            content = re.sub(r'<title[^>]*>(.*?)</title>', r'# \1', content, flags=re.IGNORECASE | re.DOTALL)
            content = re.sub(r'<h1[^>]*>(.*?)</h1>', r'# \1', content, flags=re.IGNORECASE | re.DOTALL)
            content = re.sub(r'<h2[^>]*>(.*?)</h2>', r'## \1', content, flags=re.IGNORECASE | re.DOTALL)
            content = re.sub(r'<h3[^>]*>(.*?)</h3>', r'### \1', content, flags=re.IGNORECASE | re.DOTALL)
            content = re.sub(r'<p[^>]*>(.*?)</p>', r'\1\n\n', content, flags=re.IGNORECASE | re.DOTALL)
            content = re.sub(r'<br[^>]*/?>', '\n', content, flags=re.IGNORECASE)
            content = re.sub(r'<[^>]+>', '', content)  # ë‚˜ë¨¸ì§€ íƒœê·¸ ì œê±°
            content = re.sub(r'\n\s*\n\s*\n', '\n\n', content)  # ë¹ˆ ì¤„ ì •ë¦¬
            
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(content.strip())
                
        except Exception as e:
            logger.warning(f"âš ï¸ ê¸°ë³¸ HTMLâ†’MD ë³€í™˜ ì‹¤íŒ¨ {html_file.name}: {e}")
    
    def _backup_assets_to_obsidian(self) -> dict:
        """ğŸ¨ Assets ë°±ì—…"""
        logger.info("ğŸ¨ Assets ë°±ì—… ì‹œì‘...")
        
        copied_count = 0
        
        try:
            if self.assets_dir.exists():
                # assets í´ë” ì „ì²´ë¥¼ Obsidianìœ¼ë¡œ ë³µì‚¬
                for item in self.assets_dir.rglob("*"):
                    if item.is_file():
                        relative_path = item.relative_to(self.assets_dir)
                        dst_file = self.obsidian_assets / relative_path
                        dst_file.parent.mkdir(parents=True, exist_ok=True)
                        
                        if (not dst_file.exists() or 
                            item.stat().st_mtime > dst_file.stat().st_mtime):
                            
                            shutil.copy2(item, dst_file)
                            copied_count += 1
                            logger.info(f"ğŸ¨ Asset ë³µì‚¬: {relative_path}")
            
            logger.info(f"âœ… Assets ë°±ì—… ì™„ë£Œ: {copied_count}ê°œ íŒŒì¼")
            return {
                "status": "success",
                "files_processed": copied_count,
                "message": f"Assets ë°±ì—… ì™„ë£Œ: {copied_count}ê°œ íŒŒì¼"
            }
            
        except Exception as e:
            logger.error(f"âŒ Assets ë°±ì—… ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "files_processed": 0,
                "message": f"Assets ë°±ì—… ì‹¤íŒ¨: {e}"
            }
    
    def _backup_metadata_to_obsidian(self) -> dict:
        """âš™ï¸ ë©”íƒ€ë°ì´í„° ë° ì„¤ì • ë°±ì—…"""
        logger.info("âš™ï¸ ë©”íƒ€ë°ì´í„° ë° ì„¤ì • ë°±ì—… ì‹œì‘...")
        
        copied_count = 0
        
        try:
            # ì£¼ìš” ì„¤ì • íŒŒì¼ë“¤ ë°±ì—…
            config_files = [
                "README.md",
                "manifest.webmanifest",
                "requirements.txt",
                "feed.xml",
                "sitemap.xml",
                "CNAME",
                ".nojekyll"
            ]
            
            config_backup_dir = self.obsidian_imports / "config"
            config_backup_dir.mkdir(exist_ok=True)
            
            for config_file in config_files:
                src_file = self.root_dir / config_file
                if src_file.exists():
                    dst_file = config_backup_dir / config_file
                    shutil.copy2(src_file, dst_file)
                    copied_count += 1
                    logger.info(f"âš™ï¸ ì„¤ì • ë°±ì—…: {config_file}")
            
            # GitHub ì›Œí¬í”Œë¡œìš° ë°±ì—…
            github_dir = self.root_dir / ".github"
            if github_dir.exists():
                dst_github_dir = config_backup_dir / ".github"
                if dst_github_dir.exists():
                    shutil.rmtree(dst_github_dir)
                shutil.copytree(github_dir, dst_github_dir)
                copied_count += len(list(github_dir.rglob("*")))
                logger.info("âš™ï¸ GitHub ì›Œí¬í”Œë¡œìš° ë°±ì—… ì™„ë£Œ")
            
            logger.info(f"âœ… ë©”íƒ€ë°ì´í„° ë°±ì—… ì™„ë£Œ: {copied_count}ê°œ íŒŒì¼")
            return {
                "status": "success",
                "files_processed": copied_count,
                "message": f"ë©”íƒ€ë°ì´í„° ë°±ì—… ì™„ë£Œ: {copied_count}ê°œ íŒŒì¼"
            }
            
        except Exception as e:
            logger.error(f"âŒ ë©”íƒ€ë°ì´í„° ë°±ì—… ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "files_processed": 0,
                "message": f"ë©”íƒ€ë°ì´í„° ë°±ì—… ì‹¤íŒ¨: {e}"
            }
    
    def _generate_backup_index(self, backup_summary: dict):
        """ğŸ“‹ ë°±ì—… ì¸ë±ìŠ¤ ë° ìš”ì•½ ìƒì„±"""
        logger.info("ğŸ“‹ ë°±ì—… ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        
        try:
            # ë°±ì—… ìš”ì•½ JSON ì €ì¥
            summary_file = self.obsidian_imports / "backup_summary.json"
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(backup_summary, f, ensure_ascii=False, indent=2)
            
            # ë°±ì—… ì¸ë±ìŠ¤ ë§ˆí¬ë‹¤ìš´ ìƒì„±
            index_file = self.obsidian_imports / "BACKUP_INDEX.md"
            
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            index_content = f"""# ğŸ¯ UncleParksy ì˜µì‹œë””ì–¸ ì¢…í•© ë°±ì—… ì¸ë±ìŠ¤
            
**ë°±ì—… ì™„ë£Œ ì‹œê°„**: {timestamp}
**ì´ ì²˜ë¦¬ íŒŒì¼**: {backup_summary['total_files']}ê°œ

## ğŸ“Š ë°±ì—… êµ¬ì„± ìš”ì†Œ

"""
            
            for component, result in backup_summary["components"].items():
                status_emoji = "âœ…" if result["status"] == "success" else "âŒ"
                index_content += f"### {status_emoji} {component.replace('_', ' ').title()}\n"
                index_content += f"- **ìƒíƒœ**: {result['status']}\n"
                index_content += f"- **ì²˜ë¦¬ íŒŒì¼**: {result['files_processed']}ê°œ\n"
                index_content += f"- **ë©”ì‹œì§€**: {result['message']}\n\n"
            
            index_content += f"""
## ğŸ“ ë°±ì—… ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
_obsidian/_imports/
â”œâ”€â”€ ğŸ“„ backup/          # Tistory RSS ë°±ì—… íŒŒì¼
â”œâ”€â”€ ğŸ“š archive/         # ì•„ì¹´ì´ë¸Œ HTML íŒŒì¼
â”œâ”€â”€ ğŸ—‚ï¸ html_raw/        # ì¹´í…Œê³ ë¦¬ ì›ë³¸ HTML
â”œâ”€â”€ ğŸ“ html_md/         # ì¹´í…Œê³ ë¦¬ Markdown ë³€í™˜
â”œâ”€â”€ ğŸ¨ assets/          # ë¦¬ì†ŒìŠ¤ íŒŒì¼
â”œâ”€â”€ âš™ï¸ config/          # ì„¤ì • ë° ë©”íƒ€ë°ì´í„°
â”œâ”€â”€ ğŸ“‹ backup_summary.json   # ë°±ì—… ìš”ì•½ ë°ì´í„°
â””â”€â”€ ğŸ“ backup.log       # ë°±ì—… ë¡œê·¸
```

## ğŸš€ ì‚¬ìš©ë²•

1. **Obsidianì—ì„œ ë³¼íŠ¸ ì—´ê¸°**: `_obsidian/_imports` í´ë”ë¥¼ Obsidian ë³¼íŠ¸ë¡œ ì„¤ì •
2. **ì½˜í…ì¸  íƒìƒ‰**: ê° í•˜ìœ„ í´ë”ì—ì„œ ë°±ì—…ëœ ì½˜í…ì¸  í™•ì¸
3. **ê²€ìƒ‰ í™œìš©**: Obsidianì˜ ê°•ë ¥í•œ ê²€ìƒ‰ ê¸°ëŠ¥ìœ¼ë¡œ ì½˜í…ì¸  íƒìƒ‰

## ğŸ“± ì—°ë™ ì •ë³´

- **GitHub Repository**: https://github.com/dtslib1979/UncleParksy
- **ì›¹ì‚¬ì´íŠ¸**: https://parksy.kr
- **ì‘ê°€ì§€ë§ìƒ ë°•ì”¨ì˜ ë§ˆê°ì‘ì—… ì‹œìŠ¤í…œ**

---
*ğŸ¤– ìë™ ìƒì„±ëœ ë°±ì—… ì¸ë±ìŠ¤ - {timestamp}*
"""
            
            with open(index_file, 'w', encoding='utf-8') as f:
                f.write(index_content)
            
            logger.info("âœ… ë°±ì—… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë°±ì—… ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")


def main():
    """ğŸš€ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¯ ===== UncleParksy ì˜µì‹œë””ì–¸ ì¢…í•© ë°±ì—… ì‹œìŠ¤í…œ =====")
    print("ğŸ“ í˜„ì¬ ì„¤ì •ì— ë”°ë¼ ëª¨ë“  ì½˜í…ì¸ ë¥¼ Obsidianìœ¼ë¡œ ë°±ì—…í•©ë‹ˆë‹¤")
    print("ğŸš€ ì‘ê°€ì§€ë§ìƒ ë°•ì”¨ì˜ ë§ˆê°ì‘ì—…ì„ ìœ„í•œ í†µí•© ë°±ì—… ì†”ë£¨ì…˜\n")
    
    backup_system = ObsidianComprehensiveBackup()
    success = backup_system.run_comprehensive_backup()
    
    if success:
        print("\nğŸ‰ ===== ì¢…í•© ë°±ì—… ì™„ë£Œ! =====")
        print("âœ… ëª¨ë“  ì½˜í…ì¸ ê°€ Obsidian í˜•ì‹ìœ¼ë¡œ ë°±ì—…ë˜ì—ˆìŠµë‹ˆë‹¤")
        print("ğŸ“ ë°±ì—… ìœ„ì¹˜: _obsidian/_imports/")
        print("ğŸ“‹ ë°±ì—… ìƒì„¸: _obsidian/_imports/BACKUP_INDEX.md")
        print("ğŸš€ Obsidianì—ì„œ _obsidian/_imports í´ë”ë¥¼ ë³¼íŠ¸ë¡œ ì—´ì–´ë³´ì„¸ìš”!")
        return 0
    else:
        print("\nâŒ ë°±ì—… ì‹¤íŒ¨")
        print("ğŸ“ ë¡œê·¸ í™•ì¸: _obsidian/_imports/backup.log")
        return 1


if __name__ == "__main__":
    exit(main())