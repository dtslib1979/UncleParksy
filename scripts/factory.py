#!/usr/bin/env python3
"""
DTSLIB Publisher Core - Factory Engine
ì½˜í…ì¸  ê³µì¥ì˜ í•µì‹¬ ì—”ì§„

ì‚¬ìš©ë²•:
    python scripts/factory.py throw "ì˜¤ëŠ˜ ìƒê°í•œ ê²ƒ..."     # ë˜ì§€ê¸°
    python scripts/factory.py throw --voice recording.m4a  # ìŒì„± ë˜ì§€ê¸°
    python scripts/factory.py process                       # ì²˜ë¦¬í•˜ê¸°
    python scripts/factory.py status                        # ìƒíƒœ ë³´ê¸°
    python scripts/factory.py publish src-20250116-001      # ì¶œíŒí•˜ê¸°
"""

import os
import sys
import json
import argparse
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, List
import hashlib
import re

# === ê²½ë¡œ ì„¤ì • ===
ROOT = Path(__file__).parent.parent
INBOX = ROOT / "inbox"
PROCESS = ROOT / "process"
OUTPUT = ROOT / "output"
PIPELINES = ROOT / "pipelines"

# === ë¼ìš°íŒ… í‚¤ì›Œë“œ ===
PARKSY_KEYWORDS = ["ì¼ìƒ", "ì˜¤ëŠ˜", "ìƒê°", "ëŠë‚Œ", "ì‹¤í—˜", "ë¡œê·¸", "ë‚˜ëŠ”", "ê°ì •", "í˜ë“¤", "ì¢‹ì•„", "ì‹«ì–´"]
EAE_KEYWORDS = ["ì´ë¡ ", "ë°©ë²•", "ì²´ê³„", "êµ¬ì¡°", "í”„ë ˆì„ì›Œí¬", "ëª¨ë¸", "ì„¤ê³„", "ì‹œìŠ¤í…œ", "ì›ì¹™", "ì •ì˜"]
DTSLIB_KEYWORDS = ["ì¶œíŒ", "ì±…", "ê°•ì¢Œ", "íŒë§¤", "ì›¹íˆ°", "ì‹œë¦¬ì¦ˆ", "ìƒí’ˆ", "ê°•ì˜", "êµìœ¡", "ì™„ì„±"]


class Factory:
    """ì½˜í…ì¸  ê³µì¥"""

    def __init__(self):
        self._ensure_dirs()

    def _ensure_dirs(self):
        """ë””ë ‰í† ë¦¬ í™•ì¸"""
        for subdir in ["voice", "text", "visual", "mixed"]:
            (INBOX / subdir).mkdir(parents=True, exist_ok=True)
        for subdir in ["queue", "working", "done"]:
            (PROCESS / subdir).mkdir(parents=True, exist_ok=True)
        for domain in ["parksy", "eae", "dtslib"]:
            (OUTPUT / domain).mkdir(parents=True, exist_ok=True)

    def _generate_id(self) -> str:
        """ì›ì„ ID ìƒì„±"""
        date = datetime.now().strftime("%Y%m%d")
        # ì˜¤ëŠ˜ ìƒì„±ëœ ì›ì„ ê°œìˆ˜ í™•ì¸
        existing = list(INBOX.rglob(f"src-{date}-*.json"))
        existing += list(PROCESS.rglob(f"src-{date}-*.json"))
        seq = len(existing) + 1
        return f"src-{date}-{seq:03d}"

    def _detect_domain(self, text: str, hint: Optional[str] = None) -> tuple:
        """ë„ë©”ì¸ ê°ì§€"""
        if hint and hint in ["parksy", "eae", "dtslib"]:
            return hint, 1.0, f"ì‚¬ìš©ì ì§€ì •: {hint}"

        text_lower = text.lower()
        scores = {
            "parksy": sum(1 for kw in PARKSY_KEYWORDS if kw in text_lower),
            "eae": sum(1 for kw in EAE_KEYWORDS if kw in text_lower),
            "dtslib": sum(1 for kw in DTSLIB_KEYWORDS if kw in text_lower)
        }

        total = sum(scores.values())
        if total == 0:
            return "parksy", 0.5, "ê¸°ë³¸ê°’: ìƒ˜ì—ì„œ ì‹œì‘"

        best = max(scores, key=scores.get)
        confidence = scores[best] / max(total, 1)

        reasons = {
            "parksy": "ê°ì •ì /ê°œì¸ì  ì½˜í…ì¸ ",
            "eae": "êµ¬ì¡°í™”/ì´ë¡ í™” í•„ìš”",
            "dtslib": "ìƒí’ˆí™” ê°€ëŠ¥"
        }

        return best, confidence, reasons[best]

    def _extract_keywords(self, text: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë²„ì „)"""
        # í•œê¸€ ëª…ì‚¬ ì¶”ì¶œ (ë‹¨ìˆœí™”)
        words = re.findall(r'[ê°€-í£]{2,}', text)
        # ë¹ˆë„ ê³„ì‚°
        freq = {}
        for w in words:
            freq[w] = freq.get(w, 0) + 1
        # ìƒìœ„ 10ê°œ
        sorted_words = sorted(freq.items(), key=lambda x: x[1], reverse=True)
        return [w for w, _ in sorted_words[:10]]

    def throw(
        self,
        content: str,
        input_type: str = "text",
        mood: Optional[str] = None,
        hint_domain: Optional[str] = None,
        hint_format: Optional[str] = None,
        tags: Optional[List[str]] = None
    ) -> Dict:
        """ì›ì„ ë˜ì§€ê¸°"""
        source_id = self._generate_id()

        source = {
            "id": source_id,
            "createdAt": datetime.utcnow().isoformat() + "Z",
            "input": {
                "type": input_type,
                "raw": content,
                "attachments": []
            },
            "emotion": {
                "mood": mood
            } if mood else None,
            "hint": {
                "intendedDomain": hint_domain,
                "intendedFormat": hint_format,
                "tags": tags or [],
                "note": None
            },
            "processing": {
                "status": "inbox"
            },
            "history": [
                {
                    "timestamp": datetime.utcnow().isoformat() + "Z",
                    "action": "thrown",
                    "details": "ì›ì„ì´ ê³µì¥ì— ë˜ì ¸ì§"
                }
            ]
        }

        # ì €ì¥
        target_dir = INBOX / input_type
        output_file = target_dir / f"{source_id}.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(source, f, indent=2, ensure_ascii=False)

        print(f"âœ¨ ì›ì„ ë˜ì ¸ì§: {source_id}")
        print(f"   ìœ„ì¹˜: {output_file.relative_to(ROOT)}")

        return source

    def process_one(self, source_id: str) -> Dict:
        """ë‹¨ì¼ ì›ì„ ì²˜ë¦¬"""
        # ì›ì„ ì°¾ê¸°
        source_file = None
        for pattern in [INBOX, PROCESS / "queue"]:
            for f in pattern.rglob(f"{source_id}.json"):
                source_file = f
                break

        if not source_file:
            raise FileNotFoundError(f"ì›ì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {source_id}")

        with open(source_file, "r", encoding="utf-8") as f:
            source = json.load(f)

        # ë¶„ì„
        content = source["input"]["raw"]
        hint_domain = source.get("hint", {}).get("intendedDomain")

        domain, confidence, reason = self._detect_domain(content, hint_domain)
        keywords = self._extract_keywords(content)
        word_count = len(content.split())

        # ì œëª© ì¶”ì¶œ
        lines = content.strip().split('\n')
        suggested_title = None
        for line in lines[:3]:
            line = line.strip()
            if line.startswith('#'):
                suggested_title = line.lstrip('#').strip()
                break
            elif 5 < len(line) < 80:
                suggested_title = line[:50]
                break

        # ì²˜ë¦¬ ê²°ê³¼ ì €ì¥
        source["processing"] = {
            "status": "routed",
            "analysis": {
                "detectedLanguage": "ko",
                "wordCount": word_count,
                "keywords": keywords,
                "suggestedTitle": suggested_title
            },
            "routing": {
                "domain": domain,
                "confidence": confidence,
                "reason": reason,
                "suggestedFormats": self._suggest_formats(domain, word_count)
            },
            "processedAt": datetime.utcnow().isoformat() + "Z",
            "processedBy": "factory-engine-v1"
        }

        source["history"].append({
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "action": "processed",
            "details": f"ë¼ìš°íŒ…ë¨ â†’ {domain} (ì‹ ë¢°ë„: {confidence:.2f})"
        })

        # done í´ë”ë¡œ ì´ë™
        done_file = PROCESS / "done" / f"{source_id}.json"
        with open(done_file, "w", encoding="utf-8") as f:
            json.dump(source, f, indent=2, ensure_ascii=False)

        # ì›ë³¸ ì‚­ì œ
        source_file.unlink()

        print(f"âš™ï¸  ì²˜ë¦¬ ì™„ë£Œ: {source_id}")
        print(f"   â†’ ë„ë©”ì¸: {domain}")
        print(f"   â†’ ì‹ ë¢°ë„: {confidence:.2f}")
        print(f"   â†’ ì´ìœ : {reason}")
        print(f"   â†’ í‚¤ì›Œë“œ: {', '.join(keywords[:5])}")

        return source

    def _suggest_formats(self, domain: str, word_count: int) -> List[str]:
        """ë„ë©”ì¸ê³¼ ê¸¸ì´ì— ë”°ë¥¸ í¬ë§· ì œì•ˆ"""
        if domain == "parksy":
            if word_count < 200:
                return ["log", "thought"]
            else:
                return ["essay", "log"]
        elif domain == "eae":
            if word_count < 500:
                return ["note", "definition"]
            else:
                return ["theory", "framework"]
        else:  # dtslib
            if word_count < 1000:
                return ["article", "tutorial"]
            else:
                return ["ebook-chapter", "course-script"]

    def process_all(self) -> List[Dict]:
        """ì¸ë°•ìŠ¤ì˜ ëª¨ë“  ì›ì„ ì²˜ë¦¬"""
        results = []
        for input_type in ["text", "voice", "visual", "mixed"]:
            inbox_dir = INBOX / input_type
            for f in inbox_dir.glob("src-*.json"):
                source_id = f.stem
                try:
                    result = self.process_one(source_id)
                    results.append(result)
                except Exception as e:
                    print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {source_id} - {e}")
        return results

    def status(self) -> Dict:
        """ê³µì¥ ìƒíƒœ"""
        inbox_count = sum(len(list((INBOX / t).glob("*.json"))) for t in ["text", "voice", "visual", "mixed"])
        queue_count = len(list((PROCESS / "queue").glob("*.json")))
        done_count = len(list((PROCESS / "done").glob("*.json")))

        domain_counts = {}
        for domain in ["parksy", "eae", "dtslib"]:
            domain_counts[domain] = len(list((OUTPUT / domain).glob("*"))) - 1  # TEMPLATE.md ì œì™¸

        # ë¼ìš°íŒ… í†µê³„
        routing_stats = {"parksy": 0, "eae": 0, "dtslib": 0}
        for f in (PROCESS / "done").glob("*.json"):
            with open(f, "r", encoding="utf-8") as fp:
                data = json.load(fp)
                domain = data.get("processing", {}).get("routing", {}).get("domain")
                if domain in routing_stats:
                    routing_stats[domain] += 1

        return {
            "inbox": inbox_count,
            "queue": queue_count,
            "processed": done_count,
            "output": domain_counts,
            "routing": routing_stats,
            "timestamp": datetime.utcnow().isoformat() + "Z"
        }

    def publish(self, source_id: str) -> Dict:
        """ì›ì„ì„ ì¶œíŒë¬¼ë¡œ ë³€í™˜"""
        # ì²˜ë¦¬ëœ ì›ì„ ì°¾ê¸°
        source_file = PROCESS / "done" / f"{source_id}.json"
        if not source_file.exists():
            raise FileNotFoundError(f"ì²˜ë¦¬ëœ ì›ì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {source_id}")

        with open(source_file, "r", encoding="utf-8") as f:
            source = json.load(f)

        domain = source["processing"]["routing"]["domain"]
        suggested_title = source["processing"]["analysis"].get("suggestedTitle", "ì œëª© ì—†ìŒ")
        content = source["input"]["raw"]

        # ì¶œë ¥ íŒŒì¼ ìƒì„±
        date_str = datetime.now().strftime("%Y-%m-%d")
        slug = re.sub(r'[^ê°€-í£a-z0-9]+', '-', suggested_title.lower())[:30]
        output_filename = f"{date_str}-{slug}.md"
        output_path = OUTPUT / domain / output_filename

        # í…œí”Œë¦¿ ì ìš©
        if domain == "parksy":
            output_content = f"""---
domain: parksy
type: log
source: {source_id}
created: {source['createdAt']}
published: {datetime.utcnow().isoformat()}Z
mood: {source.get('emotion', {}).get('mood', 'unknown')}
tags: {source['processing']['analysis']['keywords'][:5]}
---

# {suggested_title}

{content}

---

> ì´ ê¸€ì€ parksy.krì—ì„œ íƒœì–´ë‚¬ìŠµë‹ˆë‹¤.
> ë‚ ê²ƒ ê·¸ëŒ€ë¡œ, ì˜¤ëŠ˜ì˜ ë‚˜.
"""
        elif domain == "eae":
            output_content = f"""---
domain: eae
type: note
source: {source_id}
created: {source['createdAt']}
published: {datetime.utcnow().isoformat()}Z
framework: EduArt
tags: {source['processing']['analysis']['keywords'][:5]}
reusable: true
---

# {suggested_title}

## ê°œìš”

{content[:500]}...

## êµ¬ì¡°

(êµ¬ì¡°í™” í•„ìš”)

## ì ìš©

(ì ìš© ë°©ì•ˆ)

---

> EduArt Engineer Framework
> Beyond AI â€” ì„¤ëª… ê°€ëŠ¥í•œ í˜•íƒœë¡œ.
"""
        else:  # dtslib
            output_content = f"""---
domain: dtslib
type: draft
source: {source_id}
created: {source['createdAt']}
published: {datetime.utcnow().isoformat()}Z
product_id: null
status: draft
---

# {suggested_title}

## ì†Œê°œ

{content}

## êµ¬ë§¤/ì´ìš©

(ìƒí’ˆí™” ì¤€ë¹„ ì¤‘)

---

Â© DTSLIB Publishing
"""

        with open(output_path, "w", encoding="utf-8") as f:
            f.write(output_content)

        # ì›ì„ ì—…ë°ì´íŠ¸
        source["output"] = {
            "domain": domain,
            "format": "markdown",
            "path": str(output_path.relative_to(ROOT)),
            "publishedAt": datetime.utcnow().isoformat() + "Z"
        }
        source["processing"]["status"] = "published"
        source["history"].append({
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "action": "published",
            "details": f"ì¶œíŒë¨ â†’ {domain}/{output_filename}"
        })

        with open(source_file, "w", encoding="utf-8") as f:
            json.dump(source, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“š ì¶œíŒ ì™„ë£Œ: {source_id}")
        print(f"   â†’ ë„ë©”ì¸: {domain}")
        print(f"   â†’ íŒŒì¼: {output_path.relative_to(ROOT)}")

        return source


def main():
    parser = argparse.ArgumentParser(
        description="DTSLIB Publisher Core - Factory Engine",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  %(prog)s throw "ì˜¤ëŠ˜ ëŠë‚€ ê²ƒ..."              # í…ìŠ¤íŠ¸ ë˜ì§€ê¸°
  %(prog)s throw -m excited "ì•„ì´ë””ì–´!"        # ê°ì •ê³¼ í•¨ê»˜ ë˜ì§€ê¸°
  %(prog)s throw -d eae "ì´ë¡  ì •ë¦¬..."         # ë„ë©”ì¸ íŒíŠ¸ì™€ í•¨ê»˜
  %(prog)s process                              # ëª¨ë“  ì¸ë°•ìŠ¤ ì²˜ë¦¬
  %(prog)s status                               # ê³µì¥ ìƒíƒœ í™•ì¸
  %(prog)s publish src-20250116-001             # ì¶œíŒí•˜ê¸°
        """
    )

    subparsers = parser.add_subparsers(dest="command", help="ëª…ë ¹")

    # throw
    throw_parser = subparsers.add_parser("throw", help="ì›ì„ ë˜ì§€ê¸°")
    throw_parser.add_argument("content", nargs="?", help="ë˜ì§ˆ ë‚´ìš©")
    throw_parser.add_argument("-f", "--file", type=Path, help="íŒŒì¼ì—ì„œ ì½ê¸°")
    throw_parser.add_argument("-t", "--type", default="text",
        choices=["text", "voice", "visual", "mixed"], help="ì…ë ¥ íƒ€ì…")
    throw_parser.add_argument("-m", "--mood",
        choices=["excited", "calm", "frustrated", "curious", "urgent", "reflective"],
        help="ê°ì • ìƒíƒœ")
    throw_parser.add_argument("-d", "--domain",
        choices=["parksy", "eae", "dtslib"], help="ë„ë©”ì¸ íŒíŠ¸")
    throw_parser.add_argument("--tags", nargs="+", help="íƒœê·¸")

    # process
    process_parser = subparsers.add_parser("process", help="ì›ì„ ì²˜ë¦¬í•˜ê¸°")
    process_parser.add_argument("source_id", nargs="?", help="íŠ¹ì • ì›ì„ ID (ì—†ìœ¼ë©´ ì „ì²´)")

    # status
    subparsers.add_parser("status", help="ê³µì¥ ìƒíƒœ í™•ì¸")

    # publish
    publish_parser = subparsers.add_parser("publish", help="ì¶œíŒí•˜ê¸°")
    publish_parser.add_argument("source_id", help="ì›ì„ ID")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        sys.exit(1)

    factory = Factory()

    print()
    print("â•" * 50)
    print("  DTSLIB Publisher Core - Factory Engine")
    print("â•" * 50)
    print()

    if args.command == "throw":
        content = args.content
        if args.file:
            with open(args.file, "r", encoding="utf-8") as f:
                content = f.read()

        if not content:
            print("âŒ ë˜ì§ˆ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)

        factory.throw(
            content=content,
            input_type=args.type,
            mood=args.mood,
            hint_domain=args.domain,
            tags=args.tags
        )

    elif args.command == "process":
        if args.source_id:
            factory.process_one(args.source_id)
        else:
            results = factory.process_all()
            print(f"\nì´ {len(results)}ê°œ ì›ì„ ì²˜ë¦¬ë¨")

    elif args.command == "status":
        status = factory.status()
        print("ğŸ“Š ê³µì¥ ìƒíƒœ")
        print()
        print(f"  ì¸ë°•ìŠ¤: {status['inbox']}ê°œ")
        print(f"  ëŒ€ê¸°ì—´: {status['queue']}ê°œ")
        print(f"  ì²˜ë¦¬ë¨: {status['processed']}ê°œ")
        print()
        print("  ë¼ìš°íŒ… í˜„í™©:")
        for domain, count in status['routing'].items():
            bar = "â–ˆ" * count + "â–‘" * (10 - min(count, 10))
            print(f"    {domain:8} [{bar}] {count}")
        print()
        print("  ì¶œíŒ í˜„í™©:")
        for domain, count in status['output'].items():
            print(f"    {domain:8}: {count}ê°œ")

    elif args.command == "publish":
        factory.publish(args.source_id)

    print()
    print("â•" * 50)


if __name__ == "__main__":
    main()
